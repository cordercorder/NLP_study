{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.FashionMNIST(\"/data/rrjin/corpus_data\", download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.FashionMNIST(\"/data/rrjin/corpus_data\", download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.colors.Colormap.is_gray(self)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matplotlib.colors.Colormap.is_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = torch.rand(size=(3, 5), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = torch.empty(size=(3, ), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([140165472778344,  94476646051664,               0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target.random_(to=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3982, 0.1868, 0.0692, 0.5056, 0.3700],\n",
       "        [0.3090, 0.9699, 0.6408, 0.5046, 0.3389],\n",
       "        [0.3148, 0.0810, 0.1375, 0.9340, 0.7513]], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4197, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(test_inputs, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"/data/rrjin/run/fashion_mnist_experiment_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "\n",
       "\n",
       "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "\n",
       "\n",
       "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
       "\n",
       "\n",
       "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_grid = torchvision.utils.make_grid(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib_imshow(img_grid, one_channel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image(\"four_fashion_mnist_images\", img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /data/rrjin/corpus_data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 2, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_n_random(data, labels, n = 100):\n",
    "    \n",
    "    assert len(data) == len(labels)\n",
    "    \n",
    "    perm = torch.randperm(len(data))\n",
    "    \n",
    "    return data[perm][:n], labels[perm][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = select_n_random(trainset.data, trainset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [classes[lab] for lab in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = images.view(size=(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 28, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_embedding(features, metadata=class_labels, label_img=images.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    \n",
    "    output = net(images)\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    \n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    print(preds.shape, output.size())\n",
    "    \n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_preds(net, images, labels):\n",
    "    \n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    \n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        \n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(classes[preds[idx]], probs[idx]*100.0, classes[labels[idx]]), color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "(4,) torch.Size([4, 10])\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "\n",
    "for epoch in range(1):\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            \n",
    "            writer.add_scalar(\"training loss\", running_loss/1000, epoch*len(trainloader)+1 + i)\n",
    "            \n",
    "            writer.add_figure(\"predictions vs. actuals\", plot_class_preds(net, inputs, labels), epoch*len(trainloader)+1 + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Finished\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probs = []\n",
    "class_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    for data in testloader:\n",
    "        \n",
    "        images, labels = data\n",
    "        output = net(images)\n",
    "        \n",
    "        class_probs_batch = [F.softmax(el, dim=0) for el in output]\n",
    "        \n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "        \n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "        \n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_preds = torch.cat(class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pr_curve_tensorboard(class_index, test_probs, test_preds, global_step=0):\n",
    "    \n",
    "    tensorboard_preds = test_preds == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index], tensorboard_preds, tensorboard_probs, global_step=global_step)\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
